{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Vulnerability Detection using Deep Learning (Experiment Replication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is from Russell et. al work (Automated Vulnerability Detection in Source Code Using Deep Representation Learning) https://arxiv.org/abs/1807.04320\n",
    "* Datasets downloaded from https://osf.io/d45bw/\n",
    "* Datasets distribution: Training (80%), Validation (10%), Testing (10%)\n",
    "* The dataset consists of the source code of 1.27 million functions mined from open source software, labeled by static analysis for potential vulnerabilities.\n",
    "* Each function's raw source code, starting from the function name, is stored as a variable-length UTF-8 string. Five binary 'vulnerability' labels are provided for each function, corresponding to the four most common CWEs in our data plus all others: \n",
    " * CWE-120 (3.7% of functions)\n",
    " * CWE-119 (1.9% of functions)\n",
    " * CWE-469 (0.95% of functions)\n",
    " * CWE-476 (0.21% of functions)\n",
    " * CWE-other (2.7% of functions)\n",
    "* Functions may have more than one detected CWE each.\n",
    "* Python 3.6 and Tensorflow 2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the HDF5 files for training/validation/testing datasets to python pickle for ease of future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 datasets available\n",
    "\n",
    "data = h5py.File(\"VDISC_train.hdf5\",'r')\n",
    "#data = h5py.File(\"VDISC_validate.hdf5\",'r')\n",
    "#data = h5py.File(\"VDISC_test.hdf5\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWE-119\n",
      "CWE-120\n",
      "CWE-469\n",
      "CWE-476\n",
      "CWE-other\n",
      "functionSource\n"
     ]
    }
   ],
   "source": [
    "# List all groups\n",
    "data.visit(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe from the HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = pd.DataFrame(list(data['functionSource']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['CWE-119']=list(data['CWE-119']); mydf['CWE-120']=list(data['CWE-120']); mydf['CWE-469']=list(data['CWE-469']); mydf['CWE-476']=list(data['CWE-476']); mydf['CWE-other']=list(data['CWE-other']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.rename(columns={0:'functionSource'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionSource</th>\n",
       "      <th>CWE-119</th>\n",
       "      <th>CWE-120</th>\n",
       "      <th>CWE-469</th>\n",
       "      <th>CWE-476</th>\n",
       "      <th>CWE-other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear_area(int startx, int starty, int xsize, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReconstructDuList(Statement* head)\\n{\\n    Sta...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free_speaker(void)\\n{\\n   if(Lengths)\\n       ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlx4_register_device(struct mlx4_dev *dev)\\n{\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parse_Env_Var(void)\\n{\\n  char *p = getenv(\"LI...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      functionSource  CWE-119  CWE-120  \\\n",
       "0  clear_area(int startx, int starty, int xsize, ...    False    False   \n",
       "1  ReconstructDuList(Statement* head)\\n{\\n    Sta...    False    False   \n",
       "2  free_speaker(void)\\n{\\n   if(Lengths)\\n       ...    False    False   \n",
       "3  mlx4_register_device(struct mlx4_dev *dev)\\n{\\...    False    False   \n",
       "4  Parse_Env_Var(void)\\n{\\n  char *p = getenv(\"LI...     True     True   \n",
       "\n",
       "   CWE-469  CWE-476  CWE-other  \n",
       "0    False    False      False  \n",
       "1    False    False      False  \n",
       "2    False    False      False  \n",
       "3    False    False      False  \n",
       "4    False    False       True  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf.iloc[0:5,0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.to_pickle(\"VDISC_train.pickle\")\n",
    "#mydf.to_pickle(\"VDISC_validate.pickle\")\n",
    "#mydf.to_pickle(\"VDISC_test.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_pickle(\"VDISC_train.pickle\")\n",
    "validate=pd.read_pickle(\"VDISC_validate.pickle\")\n",
    "test=pd.read_pickle(\"VDISC_test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONTINUE LATER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorlfow version:  2.0.0\n",
      "Eager mode:  True\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "import pickle\n",
    "\n",
    "print(\"Tensorlfow version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting static and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is: 71926\n"
     ]
    }
   ],
   "source": [
    "# Generate random seed\n",
    "#myrand=np.random.randint(1, 99999 + 1)\n",
    "myrand=71926\n",
    "np.random.seed(myrand)\n",
    "tf.random.set_seed(myrand)\n",
    "print(\"Random seed is:\",myrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the global value\n",
    "WORDS_SIZE=10000\n",
    "INPUT_SIZE=500\n",
    "NUM_CLASSES=2\n",
    "MODEL_NUM=0\n",
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_pickle(\"VDISC_train.pickle\")\n",
    "validate=pd.read_pickle(\"VDISC_validate.pickle\")\n",
    "test=pd.read_pickle(\"VDISC_test.pickle\")\n",
    "\n",
    "for dataset in [train,validate,test]:\n",
    "    for col in range(1,6):\n",
    "        dataset.iloc[:,col] = dataset.iloc[:,col].map({False: 0, True: 1})\n",
    "\n",
    "# Create source code sdata for tokenization\n",
    "x_all = train['functionSource']\n",
    "#x_all = x_all.append(validate['functionSource'])\n",
    "#x_all = x_all.append(test['functionSource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000185\n",
       "1      19286\n",
       "Name: CWE-119, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of the datasets\n",
    "pd.value_counts(train.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = train[train.iloc[:,1]==1].index.values.astype(int)\n",
    "zero = train[train.iloc[:,1]==0].index.values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the source codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  1094129\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer with word-level\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts(list(x_all))\n",
    "del(x_all)\n",
    "print('Number of tokens: ',len(tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing to top N words\n",
    "tokenizer.num_words = WORDS_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('if', 3908040),\n",
       " ('0', 2633095),\n",
       " ('return', 2182544),\n",
       " ('i', 1720280),\n",
       " ('1', 1483872),\n",
       " ('int', 1271988),\n",
       " ('null', 1222633),\n",
       " ('the', 990541),\n",
       " ('t', 917046),\n",
       " ('n', 892342)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 words\n",
    "sorted(tokenizer.word_counts.items(), key=lambda x:x[1], reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequence files from the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokkenizing train data and create matrix\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(train['functionSource'])\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(list_tokenized_train, \n",
    "                                  maxlen=INPUT_SIZE,\n",
    "                                  padding='post')\n",
    "x_train = x_train.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokkenizing test data and create matrix\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(test['functionSource'])\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(list_tokenized_test, \n",
    "                                 maxlen=INPUT_SIZE,\n",
    "                                 padding='post')\n",
    "x_test = x_test.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokkenizing validate data and create matrix\n",
    "list_tokenized_validate = tokenizer.texts_to_sequences(validate['functionSource'])\n",
    "x_validate = tf.keras.preprocessing.sequence.pad_sequences(list_tokenized_validate, \n",
    "                                 maxlen=INPUT_SIZE,\n",
    "                                 padding='post')\n",
    "x_validate = x_validate.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0    1000185\n",
      "1      19286\n",
      "Name: CWE-119, dtype: int64\n",
      "\n",
      "Test 0    124967\n",
      "1      2452\n",
      "Name: CWE-119, dtype: int64\n",
      "\n",
      "Validate 0    125057\n",
      "1      2419\n",
      "Name: CWE-119, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "print('Train', pd.value_counts(train.iloc[:,1]))\n",
    "print('\\nTest', pd.value_counts(test.iloc[:,1]))\n",
    "print('\\nValidate', pd.value_counts(validate.iloc[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Enconding (OHE) on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]\n",
    "y_test=[]\n",
    "y_validate=[]\n",
    "\n",
    "for col in range(1,6):\n",
    "    y_train.append(tf.keras.utils.to_categorical(train.iloc[:,col], num_classes=NUM_CLASSES).astype(np.int64))\n",
    "    y_test.append(tf.keras.utils.to_categorical(test.iloc[:,col], num_classes=NUM_CLASSES).astype(np.int64))\n",
    "    y_validate.append(tf.keras.utils.to_categorical(validate.iloc[:,col], num_classes=NUM_CLASSES).astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    124967\n",
       "1      2452\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data\n",
    "pd.value_counts(y_test[0][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition (CNN with Gaussian Noise and 1 Output Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random weights matrix\n",
    "\n",
    "random_weights = np.random.normal(size=(WORDS_SIZE, 13),scale=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model built: \n",
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 13)           130000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 500, 512)          60416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 125, 512)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 125, 512)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4096064   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,287,537\n",
      "Trainable params: 4,287,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Must use non-sequential model building to create branches in the output layer\n",
    "model = tf.keras.Sequential(name=\"CNN\")\n",
    "model.add(tf.keras.layers.Embedding(input_dim = WORDS_SIZE,\n",
    "                                    output_dim = 13,\n",
    "                                    weights=[random_weights],\n",
    "                                    input_length = INPUT_SIZE))\n",
    "#model.add(tf.keras.layers.GaussianNoise(stddev=0.01))\n",
    "model.add(tf.keras.layers.Convolution1D(filters=512, kernel_size=(9), padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=4))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Define custom optimizers\n",
    "adam = tf.keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1, decay=0.0, amsgrad=False)\n",
    "\n",
    "## Compile model with metrics\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"CNN model built: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create TensorBoard callbacks\n",
    "\n",
    "callbackdir= 'D:\\\\temp\\\\cb'\n",
    "\n",
    "tbCallback = tf.keras.callbacks.TensorBoard(log_dir=callbackdir, \n",
    "                         histogram_freq=1,\n",
    "                         embeddings_freq=1,\n",
    "                         write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "tbCallback.set_model(model)\n",
    "mld = 'model/model-epoch-100-{epoch:02d}-single.hdf5'\n",
    "\n",
    "## Create best model callback\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(filepath=mld, \n",
    "                                         monitor=\"val_loss\",\n",
    "                                         save_best_only=True, \n",
    "                                         mode='auto', \n",
    "                                         save_freq='epoch', \n",
    "                                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1019471 samples, validate on 127476 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.169683). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09089, saving model to model/model-epoch-100-01-single.hdf5\n",
      "1019471/1019471 - 171s - loss: 0.1075 - accuracy: 0.9806 - val_loss: 0.0909 - val_accuracy: 0.9810\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09089 to 0.09022, saving model to model/model-epoch-100-02-single.hdf5\n",
      "1019471/1019471 - 168s - loss: 0.0901 - accuracy: 0.9811 - val_loss: 0.0902 - val_accuracy: 0.9810\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09022 to 0.09010, saving model to model/model-epoch-100-03-single.hdf5\n",
      "1019471/1019471 - 168s - loss: 0.0897 - accuracy: 0.9811 - val_loss: 0.0901 - val_accuracy: 0.9810\n",
      "Epoch 4/50\n"
     ]
    }
   ],
   "source": [
    "#ceiling = 38572\n",
    "#ceiling = ‭19286\n",
    "ceiling = 1019471\n",
    "\n",
    "#class_weights = {0: 1., 1: 5.}\n",
    "\n",
    "history = model.fit(x = x_train[[*one,*zero[0:ceiling]],:],\n",
    "          y = train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(),\n",
    "          validation_data = (x_validate, validate.iloc[:,1].to_numpy()),\n",
    "          epochs = 50,\n",
    "          batch_size = 128,\n",
    "          verbose =2,\n",
    "          #class_weight= class_weights,\n",
    "          callbacks=[mcp,tbCallback])\n",
    "\n",
    "with open('history/history-Epoch200-CNN-single', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Continue Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training for another 100 epochs\n",
    "\n",
    "history40 = model.fit(x = x_train[[*one,*zero[0:ceiling]],:],\n",
    "          y = train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(),\n",
    "          validation_data = (x_validate, validate.iloc[:,1].to_numpy()),\n",
    "          epochs = 20,\n",
    "          batch_size = 128,\n",
    "          verbose =2,\n",
    "          class_weight= class_weights,\n",
    "          callbacks=[mcp,tbCallback])\n",
    "\n",
    "with open('history/history-Epoch40-CNN-single', 'wb') as file_pi:\n",
    "    pickle.dump(history40.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model(\"model/model-epoch-100-15-single.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_train[[*one,*zero[0:ceiling]],:], train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), verbose=0, batch_size=128, )\n",
    "for num in range(0,len(model.metrics_names)):\n",
    "    print(model.metrics_names[num]+': '+str(results[num]))\n",
    "\n",
    "predicted = model.predict_classes(x_train[[*one,*zero[0:ceiling]],:])\n",
    "predicted_prob = model.predict(x_train[[*one,*zero[0:ceiling]],:])\n",
    "\n",
    "print('\\nConfusion Matrix')\n",
    "#predicted = model.predict_classes(x_test)\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_pred=predicted)\n",
    "print(confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_pred=predicted)))\n",
    "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_pred=predicted)))\n",
    "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_pred=predicted)))\n",
    "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_pred=predicted)))\n",
    "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_score=predicted_prob)))\n",
    "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_score=predicted_prob)))\n",
    "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=train.iloc[[*one,*zero[0:ceiling]],1].to_numpy(), y_pred=predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation using Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.07753969002523994\n",
      "accuracy: 0.9675951\n",
      "[[121550   3417]\n",
      " [   712   1740]]\n",
      "\n",
      "TP: 1740\n",
      "FP: 3417\n",
      "TN: 121550\n",
      "FN: 712\n",
      "\n",
      "Accuracy: 0.967595099631923\n",
      "Precision: 0.33740546829552065\n",
      "Recall: 0.7096247960848288\n",
      "F-measure: 0.4573531344460507\n",
      "Precision-Recall AUC: 0.3717378299548528\n",
      "AUC: 0.9436436472083443\n",
      "MCC: 0.4756387578525323\n"
     ]
    }
   ],
   "source": [
    "## Test data\n",
    "\n",
    "results = model.evaluate(x_test, test.iloc[:,1].to_numpy(), batch_size=128)\n",
    "for num in range(0,len(model.metrics_names)):\n",
    "    print(model.metrics_names[num]+': '+str(results[num]))\n",
    "\n",
    "predicted = model.predict_classes(x_test)\n",
    "predicted_prob = model.predict(x_test)\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=test.iloc[:,1].to_numpy(), y_pred=predicted)\n",
    "print(confusion)\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=test.iloc[:,1].to_numpy(), y_pred=predicted)))\n",
    "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=test.iloc[:,1].to_numpy(), y_pred=predicted)))\n",
    "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=test.iloc[:,1].to_numpy(), y_pred=predicted)))\n",
    "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=test.iloc[:,1].to_numpy(), y_pred=predicted)))\n",
    "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=test.iloc[:,1].to_numpy(), y_score=predicted_prob)))\n",
    "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=test.iloc[:,1].to_numpy(), y_score=predicted_prob)))\n",
    "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=test.iloc[:,1].to_numpy(), y_pred=predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot The Model's Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(len(history.history[model.metrics_names[1]]))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20,15))\n",
    "fig.suptitle('CNN with 20 Epochs')\n",
    "\n",
    "axs[0,0].plot(epochs_range, history.history[model.metrics_names[0]], 'b', label='Loss', color='red')\n",
    "axs[0,0].plot(epochs_range, history.history[model.metrics_names[1]], 'b', label='Accuracy', color='green')\n",
    "axs[0,0].set_title('Training accuracy & loss - CW-E119')\n",
    "axs[0,0].legend()\n",
    "\n",
    "\n",
    "axs[0,1].plot(epochs_range, history.history['val_%s'%(model.metrics_names[0])], 'b', label='Loss', color='red')\n",
    "axs[0,1].plot(epochs_range, history.history['val_%s'%(model.metrics_names[1])], 'b', label='Accuray', color='green')\n",
    "axs[0,1].set_title('Validation accuracy & loss - CWE-119')\n",
    "axs[0,1].legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion (Test results only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| No.|Weights (0 : 1)|TP|FP|TN|FN|Acc|Precision|Recall|PR-AUC|AUC|MCC|F1|\n",
    "|---\t|---\t|---\t|---\t|---\t|---\t|---\t|---\t|---\t|---\t|---\t|---\t|---\t|\n",
    "|  1 \t| 1 : 50  \t|  2090   \t|  9883  \t| 115084  \t|362| 0.9195  \t|  0.1745  \t| 0.8523 \t| 0.3272| 0.9433|0.3640| 0.2897|\n",
    "|  2 \t| 1 : 35  \t|  2089\t    |  8480  \t| 116487  \t|363| 0.9305   \t|  0.1976  \t| 0.8519 \t| 0.3516| 0.9450|0.3905| 0.3208|\n",
    "|  3\t| 1 : 25   \t|  2055 \t|  7442  \t| 117525  \t|397| 0.9384  \t|  0.2163 \t| 0.8380  \t| 0.3472| 0.9455|0.4072| 0.3439|\n",
    "|  4\t| 1 : 20   \t|  2040 \t|  6989  \t| 117978  \t|412| 0.9419  \t|  0.2259 \t| 0.8319  \t| 0.3441| 0.9459|0.4154| 0.3553|\n",
    "|  5\t| 1 : 15   \t|  1994 \t|  5937  \t| 119030  \t|458| 0.9498  \t|  0.2514 \t| 0.8132  \t| 0.3533| 0.9455|0.4354| 0.3840|\n",
    "|  6\t| 1 : 10   \t|  1930 \t|  5257  \t| 119710  \t|522| 0.9546  \t|  0.2685 \t| 0.7871  \t| 0.3479| 0.9463|0.4436| 0.4004|\n",
    "|  7\t| 1 : 5   \t|  1610 \t|  3240  \t| 121727  \t|842| 0.9679  \t|  0.3319 \t| 0.6566  \t| 0.3343| 0.9430|0.4527| 0.4409|\n",
    "|  8\t| 1 : 5(40ep)|  1740 \t|  3417  \t| 121550  \t|712| 0.9675  \t|  0.3374 \t| 0.7096  \t| 0.3717| 0.9436|0.4756| 0.4573|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
